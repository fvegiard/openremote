# üß† LENA ‚Äî Plan Complet de Personnalisation et D√©ploiement

> **Objectif** : Transformer le fork d'`openremote` en un conteneur Docker portable
> nomm√© **Lena** ‚Äî un environnement IA autonome, complet avec vectorisation de docs,
> pr√™t √† migrer du laptop vers une tour ML/AI d√©di√©e ($25K).

---

## üì¶ Ce Que Le Fork Fournit D√©j√† (Base)

| Composant | Version | Status |
|---|---|---|
| OpenCode CLI | latest | ‚úÖ Install√© |
| Oh My OpenCode | latest (npm + bun) | ‚úÖ Install√© |
| Node.js | 24 | ‚úÖ Base image |
| Bun | latest | ‚úÖ Install√© |
| uv (Python) | latest | ‚úÖ Install√© |
| Neovim | nightly | ‚úÖ Install√© |
| tmux + tmuxp | latest | ‚úÖ Install√© |
| LSP Servers | TS, Tailwind, YAML, Bash, Docker, GraphQL, Prisma | ‚úÖ Install√©s |
| ttyd (web terminal) | 1.7.7 | ‚úÖ Install√© |
| SSH Server | OpenSSH | ‚úÖ Configur√© |
| Playwright + Chromium | latest | ‚úÖ Install√© |
| clawd.bot | latest | ‚úÖ Install√© |
| spec-kit | latest | ‚úÖ Install√© |
| Homebrew | latest | ‚úÖ Install√© |

### Agents Oh My OpenCode Pr√©-Configur√©s

| Agent | R√¥le | Mod√®le par d√©faut |
|---|---|---|
| **Sisyphus** | Worker autonome (ne stop jamais) | configurable |
| **Planner-Sisyphus** | Planificateur de t√¢ches | configurable |
| **Librarian** | Chercheur de docs/code | configurable (flash) |
| **Explore** | Exploration rapide du codebase | configurable (flash) |
| **Oracle** | Architecte / Debugger | configurable |
| **Frontend UI/UX Engineer** | Design & composants | configurable |
| **Document Writer** | R√©daction docs/specs | configurable (flash) |
| **Multimodal Looker** | Analyse d'images/screenshots | configurable (flash) |

---

## üîß Phase 1 ‚Äî Personnalisation de la Persona (MAINTENANT)

### 1.1 Renommer `dev` ‚Üí `lena`

**Fichiers √† modifier :**
- [ ] `Dockerfile` : `ARG USER=dev` ‚Üí `ARG USER=lena`
- [ ] `Dockerfile` : Tous les chemins `/home/dev/` ‚Üí `/home/lena/`
- [ ] `docker-compose.yaml` : `dev_home` volume ‚Üí `lena_home`  
- [ ] `docker-compose.yaml` : Service name `ohmyopencode` ‚Üí `lena`
- [ ] `scripts/entrypoint.sh` : R√©f√©rence `dev` user ‚Üí `lena`
- [ ] `.env.example` : Ajouter `LENA_` prefix pour clart√©

### 1.2 Configurer les Mod√®les IA (Persona Lena)

**Fichier :** `opencode_config/opencode.json`

```json
{
  "provider": {
    "google": {
      "models": {
        "antigravity-gemini-3-pro": { ... },
        "antigravity-gemini-3-flash": { ... }
      }
    },
    "ollama": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "Ollama (GPU Local)",
      "options": {
        "baseURL": "http://host.docker.internal:11434/v1"
      },
      "models": {
        "qwen3-coder:latest": { "name": "Qwen3 Coder (local GPU)" },
        "qwen3-vl:32b": { "name": "Qwen3 VL 32B (local GPU)" },
        "qwen3-embedding:8b": { "name": "Qwen3 Embedding 8B (local)" }
      }
    }
  }
}
```

### 1.3 Configurer les Agents Oh My OpenCode pour Lena

**Fichier :** `opencode_config/oh-my-opencode.json`

Routing des agents vers les mod√®les optimaux :
- **Workers lourds** (Sisyphus, Oracle, Planner) ‚Üí Gemini 3 Pro ou Qwen3 Coder local
- **Workers rapides** (Explore, Librarian) ‚Üí Gemini 3 Flash ou Qwen3 Coder local
- **Multimodal** ‚Üí Qwen3 VL 32B local pour analyse d'images

### 1.4 Ajouter ta Cl√© SSH

**Fichier :** `.env` (copi√© depuis `.env.example`)

```bash
SSH_PUBLIC_KEY="<contenu de ~/.ssh/id_ed25519.pub>"
GOOGLE_API_KEY="<ta cl√© Gemini>"
# Ollama tourne sur l'h√¥te, pas besoin de cl√©
```

---

## üóÑÔ∏è Phase 2 ‚Äî Vector DB pour Documentation (ENSUITE)

### 2.1 Objectif

Int√©grer dans le conteneur un serveur de vectorisation qui indexe toute la documentation
(OpenClaw, projets locaux, etc.) pour que les agents puissent chercher dedans.

### 2.2 Architecture

```
‚îå‚îÄ Conteneur Lena ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                        ‚îÇ
‚îÇ  OpenCode ‚Üê‚Üí Oh My OpenCode                            ‚îÇ
‚îÇ       ‚Üï                                                ‚îÇ
‚îÇ  MCP Server (vectordb)  ‚Üê‚Üí  SQLite + FAISS index       ‚îÇ
‚îÇ       ‚Üï                      ‚Üï                         ‚îÇ
‚îÇ  Ollama (via host)       Documents Markdown             ‚îÇ
‚îÇ                                                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 2.3 Composants √† Ajouter

- [ ] `vectordb/` ‚Äî Dossier Python avec un serveur MCP local
- [ ] `vectordb/requirements.txt` ‚Äî `faiss-cpu`, `sqlite3`, `fastapi`, `sentence-transformers`
- [ ] `vectordb/server.py` ‚Äî Serveur FastAPI expos√© sur port 8765
- [ ] `vectordb/ingest.py` ‚Äî Script d'ingestion Markdown ‚Üí embeddings
- [ ] Ajouter la config MCP dans `opencode.json` :
  ```json
  "mcp": {
    "vectordb": {
      "type": "local",
      "command": "/opt/vectordb/.venv/bin/python",
      "args": ["/opt/vectordb/server.py"]
    }
  }
  ```
- [ ] Modifier `Dockerfile` pour installer l'env Python vectordb
- [ ] Modifier `docker-compose.yaml` pour exposer le port 8765

### 2.4 Ingestion OpenClaw

1. Scraper les docs OpenClaw ‚Üí Markdown
2. Chunker les fichiers (512 tokens par chunk)
3. Embeddings via Qwen3 Embedding 8B (via Ollama sur l'h√¥te)
4. Stocker dans SQLite+FAISS index
5. Servir via MCP pour que les agents cherchent dedans

---

## üöÄ Phase 3 ‚Äî Build, Test & Portabilit√© (APR√àS)

### 3.1 Build Local

```bash
cd ~/Documents/GitHub/'antigravity dev'/opencode
cp .env.example .env
# √âditer .env avec tes cl√©s
docker compose up -d --build
```

### 3.2 Tester

```bash
# SSH dans le conteneur
ssh -p 2222 lena@localhost

# Ou via le terminal web
open http://localhost:4096

# V√©rifier OpenCode
opencode --version

# V√©rifier les agents
opencode /agents
```

### 3.3 Exporter pour la Tour ML/AI

```bash
# Sauvegarder l'image compl√®te
docker save lena-ai:latest | gzip > lena-ai-backup.tar.gz

# Sur la tour ($25K) :
docker load < lena-ai-backup.tar.gz
docker compose up -d

# Acc√®s distant depuis le laptop via Tailscale
ssh lena@<tailscale-ip>
```

### 3.4 Volumes √† Persister

| Volume | Contenu | Survit au rebuild |
|---|---|---|
| `lena_home` | Config user, historique, cl√©s | ‚úÖ Oui |
| `./workspace` | Projets de code | ‚úÖ Oui (bind mount) |
| FAISS index | Vector DB index√©e | Via volume nomm√© |

---

## üìã Phase 4 ‚Äî Enrichissements Futurs (ROADMAP)

- [ ] Ajouter Tailscale VPN dans le conteneur pour acc√®s distant
- [ ] Int√©grer GitHub Actions pour CI/CD automatique
- [ ] Ajouter monitoring (Prometheus/Grafana) pour la sant√© du conteneur
- [ ] Configurer les notifications Slack via webhook (Ralph agent)
- [ ] Multi-GPU support quand la tour arrive
- [ ] Ajouter plus de Language Servers (Python via Pyright, Go via gopls, Rust via rust-analyzer)

---

## üéØ R√©sum√© des Actions Imm√©diates

| # | Action | Fichier(s) | Effort |
|---|---|---|---|
| 1 | Renommer `dev` ‚Üí `lena` | Dockerfile, compose, entrypoint | 10 min |
| 2 | Cr√©er `opencode_config/` depuis examples | Config dir | 5 min |
| 3 | Configurer Ollama local comme provider | opencode.json | 5 min |
| 4 | Router agents vers bons mod√®les | oh-my-opencode.json | 5 min |
| 5 | Cr√©er `.env` avec tes vraies cl√©s | .env | 2 min |
| 6 | Build & test le conteneur | Terminal | 15 min |
| 7 | Push le fork personnalis√© sur GitHub | Git | 2 min |

**Total estim√© Phase 1 : ~45 minutes**

---

*Ce plan est un document vivant. Chaque phase sera ex√©cut√©e s√©quentiellement
apr√®s validation. La Phase 2 (Vector DB) sera ajout√©e au Dockerfile une fois
la Phase 1 valid√©e et fonctionnelle.*
